{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d38bcd-23c8-4101-9c86-f418943f1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392aae20-4e83-4ae0-9f96-a2b15daf8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a bangla tokenizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f3bf6-123b-44aa-8f22-de75c09b536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the llama model on the bangla dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3a570-f86f-49d4-b29a-57bb7c600ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce96bd-bf0e-4ebc-a663-5ec1a6c868bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #download unsloth\n",
    "# !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "# !pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes datasets transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe24c0-8785-40c9-9bd6-1edf1428cefc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install datasets tokenizers transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c14543-11a7-4a79-9a23-45c975177aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer, models, normalizers, pre_tokenizers, trainers, processors, decoders\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501f3d1-bc97-4bda-8856-e12bc155abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from huggingface_hub import HfApi, list_models\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from peft import get_peft_model, LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51051ef8-5cd6-4f84-8454-80a7669684ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bangla dataset\n",
    "dataset = load_dataset(\"oscar\", \"unshuffled_deduplicated_bn\", split=\"train\")\n",
    "\n",
    "#link to dataset  = https://huggingface.co/datasets/oscar-corpus/oscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ae0c9-67f2-44d1-a331-5b2005cb3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i : i + 1000][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196f38a-50d1-4fbc-8223-36ce414c2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPE tokenizer \n",
    "tokenizer = Tokenizer(models.BPE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4981263-25c1-40c5-addf-e80d6c73a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set normalizer\n",
    "tokenizer.normalizer = Sequence([\n",
    "    NFD(),\n",
    "    StripAccents(),\n",
    "    Replace(Regex(r\"[\\s]+\"), \" \"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa677e99-daa2-44a7-815c-b6d9cd6c99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set normalizer\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037660ed-eaf3-45a2-8761-91d01d870978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = trainers.BpeTrainer(vocab_size=30000, special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0040bf1-d538-4f07-91de-1ac60a2f4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tokenizer\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)\n",
    "\n",
    "# Save\n",
    "tokenizer.save(\"bangla_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be0a59-4b12-428f-b1e1-75f80ac6a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "bangla_tokenizer = Tokenizer.from_file(\"bangla_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d55e5-cc07-4a98-8a8d-9a74c24f9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the tokenizer\n",
    "bangla_tokenizer = PreTrainedTokenizerFast(tokenizer_object=bangla_tokenizer, unk_token=\"<unk>\", pad_token=\"<pad>\", cls_token=\"<s>\", sep_token=\"</s>\", mask_token=\"<mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae6ee9-5d7a-475c-9f1f-c800a172ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(examples):\n",
    "    texts = examples[\"text\"]\n",
    "    eos_token_str = bangla_tokenizer.sep_token  \n",
    "    # Tokenize the texts\n",
    "    tokenized_texts = bangla_tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    return tokenized_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb28b7d-9b35-4fe6-952d-6f9d6988399d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load and format the dataset\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"oscar\", \"unshuffled_deduplicated_bn\", split=\"train[:1%]\")\n",
    "dataset = dataset.map(format_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743ec2d-c0d9-49e9-b455-d09b2bf35c71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "from unsloth import FastLanguageModel\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511436bf-4d47-484a-89ed-f382b5cb1e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach LoRA Adapters\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47690d-67df-4f75-9f11-08bcffc64bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=bangla_tokenizer,\n",
    "    mlm=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c818c8-83da-4730-a373-7fb032058d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bangla_llama\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10_000,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"wandb\",\n",
    "    remove_unused_columns=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15dc8f6-fe00-4c4c-9686-884ce57a5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a7f7b1-416e-48a3-954b-c962f0095e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model with progress bar\n",
    "wandb.init(project=\"bangla-llama-finetuning\")\n",
    "for epoch in range(training_args.num_train_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{training_args.num_train_epochs}\")\n",
    "    trainer.train()\n",
    "\n",
    "# Save the model with progress bar\n",
    "print(\"Saving the model...\")\n",
    "trainer.save_model(\"./bangla_llama\")\n",
    "bangla_tokenizer.save(\"bangla_llama\")\n",
    "print(\"Model saved.\")\n",
    "\n",
    "# Finish Weights & Biases run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc205026-ee0d-40ca-b375-bdd646629212",
   "metadata": {},
   "outputs": [],
   "source": [
    "## part 2 - help with GPT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "db9935cc-bcd2-42fe-ae8d-12d1965bc95a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /workspace/data/huggingface-cache/hub/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jwskkaih) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">final-run</strong> at: <a href='https://wandb.ai/suvrakamal/bangla-llama-finetuning/runs/jwskkaih/workspace' target=\"_blank\">https://wandb.ai/suvrakamal/bangla-llama-finetuning/runs/jwskkaih/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240805_230224-jwskkaih/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jwskkaih). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e5258081f649498480cb9c35e6eb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113628248373668, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240805_230345-kz7z0thx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/suvrakamal/bangla-llama-finetuning/runs/kz7z0thx/workspace' target=\"_blank\">azure-rain-12</a></strong> to <a href='https://wandb.ai/suvrakamal/bangla-llama-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/suvrakamal/bangla-llama-finetuning' target=\"_blank\">https://wandb.ai/suvrakamal/bangla-llama-finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/suvrakamal/bangla-llama-finetuning/runs/kz7z0thx/workspace' target=\"_blank\">https://wandb.ai/suvrakamal/bangla-llama-finetuning/runs/kz7z0thx/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(\"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\")  # Replace with your Hugging Face token\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "wandb.init(project=\"bangla-llama-finetuning\")\n",
    "\n",
    "# Load the custom Bangla tokenizer\n",
    "bangla_tokenizer = Tokenizer.from_file(\"bangla_tokenizer.json\")\n",
    "\n",
    "# Wrap the tokenizer\n",
    "bangla_tokenizer = PreTrainedTokenizerFast(tokenizer_object=bangla_tokenizer, unk_token=\"<unk>\", pad_token=\"<pad>\", cls_token=\"<s>\", sep_token=\"</s>\", mask_token=\"<mask>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "af88b366-2438-4029-abed-ca80baa0b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for oscar contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/oscar\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"oscar\", \"unshuffled_deduplicated_bn\", split=\"train[:1%]\")\n",
    "\n",
    "# Function to format the dataset for training\n",
    "def format_dataset(examples):\n",
    "    texts = examples[\"text\"]\n",
    "    # Tokenize the texts\n",
    "    tokenized_texts = bangla_tokenizer(texts, padding=True, truncation=True, max_length=512)\n",
    "    return tokenized_texts\n",
    "\n",
    "# Apply tokenization to the dataset\n",
    "dataset = dataset.map(format_dataset, batched=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "dataset = dataset.remove_columns([\"id\", \"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "21ae973a-d579-4cd0-a909-23f057783ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA A100 80GB PCIe. Max memory: 79.151 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.2+cu118. CUDA = 8.0. CUDA Toolkit = 11.8.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.23.post1+cu118. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "# Attach LoRA Adapters\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2151b135-ff2f-4f47-b3e1-31b152a5f27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:kz7z0thx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Thread SenderThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
      "    self._process(record)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 328, in _process\n",
      "    self._sm.send(record)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 386, in send\n",
      "    send_handler(record)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 590, in send_exit\n",
      "    self._update_summary()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1162, in _update_summary\n",
      "    with open(summary_path, \"w\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/workspace/wandb/run-20240805_230345-kz7z0thx/files/wandb-summary.json'\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /tmp/ipykernel_2278/1578106915.py 7 <module>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2301, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2548, in _on_finish\n",
      "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 298, in wait\n",
      "    on_probe(probe_handle)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2512, in _on_probe_exit\n",
      "    result = handle.wait(timeout=0, release=False)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 281, in wait\n",
      "    raise MailboxError(\"transport failed\")\n",
      "wandb.sdk.lib.mailbox.MailboxError: transport failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 1187, in init\n",
      "    run = wi.init()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 602, in init\n",
      "    latest_run.finish()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2043, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2058, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2312, in _atexit_cleanup\n",
      "    self._backend.cleanup()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/backend/backend.py\", line 232, in cleanup\n",
      "    self.interface.join()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 553, in join\n",
      "    super().join()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 724, in join\n",
      "    _ = self._communicate_shutdown()\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 450, in _communicate_shutdown\n",
      "    _ = self._communicate(record)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 302, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 60, in _communicate_async\n",
      "    future = self._router.send_and_receive(rec, local=local)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/router.py\", line 94, in send_and_receive\n",
      "    self._send_message(rec)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/router_sock.py\", line 36, in _send_message\n",
      "    self._sock_client.send_record_communicate(record)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 216, in send_record_communicate\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "An unexpected error occurred",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMailboxError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2301\u001b[0m, in \u001b[0;36mRun._atexit_cleanup\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2301\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ki:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2548\u001b[0m, in \u001b[0;36mRun._on_finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# this message is confusing, we should remove it\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# self._footer_exit_status_info(\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m#     self._exit_code, settings=self._settings, printer=self._printer\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m-> 2548\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mexit_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_progress_exit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m poll_exit_handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mdeliver_poll_exit()\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py:298\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_probe \u001b[38;5;129;01mand\u001b[39;00m probe_handle:\n\u001b[0;32m--> 298\u001b[0m     \u001b[43mon_probe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobe_handle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_progress \u001b[38;5;129;01mand\u001b[39;00m progress_handle:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2512\u001b[0m, in \u001b[0;36mRun._on_probe_exit\u001b[0;34m(self, probe_handle)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle:\n\u001b[0;32m-> 2512\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py:281\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interface\u001b[38;5;241m.\u001b[39m_transport_keepalive_failed():\n\u001b[0;32m--> 281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m found, abandoned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slot\u001b[38;5;241m.\u001b[39m_get_and_clear(timeout\u001b[38;5;241m=\u001b[39mwait_timeout)\n",
      "\u001b[0;31mMailboxError\u001b[0m: transport failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1187\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1187\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:602\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    598\u001b[0m     ipython\u001b[38;5;241m.\u001b[39mdisplay_html(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinishing last run (ID:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_run\u001b[38;5;241m.\u001b[39m_run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) before initializing another...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m     )\n\u001b[0;32m--> 602\u001b[0m \u001b[43mlatest_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jupyter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39msilent:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:420\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:361\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2043\u001b[0m, in \u001b[0;36mRun.finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mark a run as finished, and finish uploading all data.\u001b[39;00m\n\u001b[1;32m   2035\u001b[0m \n\u001b[1;32m   2036\u001b[0m \u001b[38;5;124;03mThis is used when creating multiple runs in the same process. We automatically\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2041\u001b[0m \u001b[38;5;124;03m    quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   2042\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2058\u001b[0m, in \u001b[0;36mRun._finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   2056\u001b[0m         hook\u001b[38;5;241m.\u001b[39mcall()\n\u001b[0;32m-> 2058\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_atexit_cleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl\u001b[38;5;241m.\u001b[39m_global_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2312\u001b[0m, in \u001b[0;36mRun._atexit_cleanup\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_console_stop()\n\u001b[0;32m-> 2312\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2313\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem finishing run\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/backend/backend.py:232\u001b[0m, in \u001b[0;36mBackend.cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb_process:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:553\u001b[0m, in \u001b[0;36mInterfaceShared.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_router:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:724\u001b[0m, in \u001b[0;36mInterfaceBase.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 724\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate_shutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:450\u001b[0m, in \u001b[0;36mInterfaceShared._communicate_shutdown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_record(request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 450\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:302\u001b[0m, in \u001b[0;36mInterfaceShared._communicate\u001b[0;34m(self, rec, timeout, local)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_communicate\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m, rec: pb\u001b[38;5;241m.\u001b[39mRecord, timeout: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    301\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[pb\u001b[38;5;241m.\u001b[39mResult]:\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:60\u001b[0m, in \u001b[0;36mInterfaceSock._communicate_async\u001b[0;34m(self, rec, local)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe wandb backend process has shutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_router\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_and_receive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m future\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/router.py:94\u001b[0m, in \u001b[0;36mMessageRouter.send_and_receive\u001b[0;34m(self, rec, local)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_reqs[rec\u001b[38;5;241m.\u001b[39muuid] \u001b[38;5;241m=\u001b[39m future\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m future\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/interface/router_sock.py:36\u001b[0m, in \u001b[0;36mMessageSockRouter._send_message\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_send_message\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:216\u001b[0m, in \u001b[0;36mSockClient.send_record_communicate\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    215\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_communicate\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define data collator\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForLanguageModeling(\n\u001b[1;32m      3\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mbangla_tokenizer,\n\u001b[1;32m      4\u001b[0m     mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m  \u001b[38;5;66;03m# Optional: Ensure tensors are padded to be divisible by 8\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbangla-llama-finetuning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinal-run\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Define training arguments\u001b[39;00m\n\u001b[1;32m     10\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     11\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./bangla_llama\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     overwrite_output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     remove_unused_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     24\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.10/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1225\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             wandb\u001b[38;5;241m.\u001b[39mtermerror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbnormal program exit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1224\u001b[0m             os\u001b[38;5;241m.\u001b[39m_exit(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1225\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn unexpected error occurred\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror_seen\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\n",
      "\u001b[0;31mError\u001b[0m: An unexpected error occurred"
     ]
    }
   ],
   "source": [
    "# Define data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=bangla_tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8  # Optional: Ensure tensors are padded to be divisible by 8\n",
    ")\n",
    "wandb.init(project=\"bangla-llama-finetuning\", name=\"final-run\")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bangla_llama\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10_000,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"wandb\",\n",
    "    remove_unused_columns=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75dcc7-34d6-4969-ab47-5205e29e3c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
